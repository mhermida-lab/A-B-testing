{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis for Game Company XXXX  \n",
    "## Analyzing Game XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This AB test was aimed to assess whether or not increasing the difficulty in selected game's levels and offering a second chance (in case of failure) for a small amount of currency improves the overal \"quality\" of the game as the company understand it, increasing revenue without sensibly affecting user's engagement. (*this was inferred*)\n",
    "\n",
    "In order to fulfill this objective a modification in the game was proposed and it had to be tested to understand its effects.  The test offererd two diﬀerent game experiences that we called A and B, group A being the control group where the experience is kept as is, and group B being the experiment group that is exposed to the new experience.  \n",
    "We set the assignment process to randomly distribute players among the groups: 80% to group A (control) and 20% to group B (test). The experiment ran from 2017-05-04 to 2017-05-22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key metrics for this test were revenue and engagement reflected user purchases per day game rounds ended per day. The first we wanted to increase and the second to maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report is structured as follows:  \n",
    "1. Exploratory Data Analysis: Data integrity first glance insights.  \n",
    "2. Statistical Analysis.  \n",
    "3. Insights.\n",
    "4. Final conclusions and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries and reading the whole datasets to analyze\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import google.cloud.bigquery.magics\n",
    "\n",
    "google.cloud.bigquery.magics.context.use_bqstorage_api = True\n",
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery assignment\n",
    "SELECT\n",
    "  playerid,\n",
    "  abtest_group,\n",
    "  assignment_date,\n",
    "  install_date,\n",
    "  conversion_date\n",
    "FROM\n",
    "  `XXXXX`.abtest.assignment ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerid</th>\n",
       "      <th>abtest_group</th>\n",
       "      <th>assignment_date</th>\n",
       "      <th>install_date</th>\n",
       "      <th>conversion_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4075399</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8656643</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19536870</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>2016-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3207631</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31527808</td>\n",
       "      <td>A</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10331051</td>\n",
       "      <td>51066353</td>\n",
       "      <td>B</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10331052</td>\n",
       "      <td>51142855</td>\n",
       "      <td>B</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10331053</td>\n",
       "      <td>51100144</td>\n",
       "      <td>B</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10331054</td>\n",
       "      <td>51043351</td>\n",
       "      <td>B</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10331055</td>\n",
       "      <td>51092283</td>\n",
       "      <td>B</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10331056 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          playerid abtest_group assignment_date install_date conversion_date\n",
       "0          4075399            A      2017-05-04   2016-02-10            None\n",
       "1          8656643            A      2017-05-04   2016-03-26            None\n",
       "2         19536870            A      2017-05-04   2016-07-14      2016-07-19\n",
       "3          3207631            A      2017-05-04   2016-02-01            None\n",
       "4         31527808            A      2017-05-04   2016-11-10            None\n",
       "...            ...          ...             ...          ...             ...\n",
       "10331051  51066353            B      2017-05-22   2017-05-22            None\n",
       "10331052  51142855            B      2017-05-22   2017-05-22            None\n",
       "10331053  51100144            B      2017-05-22   2017-05-22            None\n",
       "10331054  51043351            B      2017-05-22   2017-05-22            None\n",
       "10331055  51092283            B      2017-05-22   2017-05-22            None\n",
       "\n",
       "[10331056 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery activity\n",
    "SELECT\n",
    "  activity.playerid,\n",
    "  activity.activity_date,\n",
    "  activity.purchases,\n",
    "  activity.gameends\n",
    "FROM\n",
    "  `XXXXX`.abtest.activity\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets were extracted from two BigQuery tables. One was the assignment table which contained useful information regarding players and the other one was the activity table focused in daily activity records of the players. This activity table contains the observations for the AB test.\n",
    "\n",
    "Assignment table exploration:  \n",
    "The assignment table contains players assigned to the A/B test and attributes related to each player.  \n",
    "• playerid: Unique numeric identiﬁer for each player  \n",
    "• abtest_group: The group the player was assigned to (A or B)  \n",
    "• assignment_date: The date when the player was assigned to the test  \n",
    "• install_date: The date when the player installed the game  \n",
    "• conversion_date: The date when the player made their ﬁrst purchase  \n",
    "\n",
    "No duplicated userids, 10.331.056 total players in selected for the test.   \n",
    "No nulls except for conversions field which was expected.  \n",
    "Assignment date was string type not datatime type.  \n",
    "All userids were assigned to a test group.  \n",
    "No assignment or conversion dates prior to install date.  \n",
    "2.859.23 players with conversions.\n",
    "\n",
    "Activity table exploration:  \n",
    "The activity table contains the test observations:  \n",
    "• playerid: Unique numeric identiﬁer for each player  \n",
    "• activity_date: The date of activity  \n",
    "• purchases: Number of purchases made this day  \n",
    "• gameends: Number of gamerounds played this day\n",
    "\n",
    "There are 214.878.701 records of which none have null values and 90.625.439 are dated before the start of the test.\n",
    "\n",
    "To proceed with deeper analysis I had to join the two tables to extract more complete information.  \n",
    "So far the data was complete, reliable and clean. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery main_dataset\n",
    "SELECT\n",
    "  activity.playerid,\n",
    "  activity.activity_date,\n",
    "  activity.purchases,\n",
    "  activity.gameends,\n",
    "  assignment.abtest_group AS ABGroup,\n",
    "  assignment.install_date,\n",
    "  assignment.conversion_date\n",
    "FROM\n",
    "  `XXXXXX`.abtest.activity\n",
    "LEFT JOIN\n",
    "  `XXXXXX`.abtest.assignment\n",
    "ON\n",
    "  activity.playerid = assignment.playerid\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main_dataset is the product of left joining Activity table with Assignment table. This way I can have usefull information attached the test observations.\n",
    "\n",
    "This dataset contained 214878701 observations of which 90625439 observations were previous to the test start.  \n",
    "The actual AB test observations were 124253262 split into the control group A (75%) with 99419615 observations and the test group B (25%) with 24833647 observations. These group observations were evenly distributed over 19 days (AB test length).\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery pre_test_activity\n",
    "SELECT \n",
    "  playerid,\n",
    "  activity_date,\n",
    "  purchases,\n",
    "  gameends,\n",
    "  ABgroup,\n",
    "  install_date,\n",
    "  conversion_date\n",
    "FROM `XXXXX.abtest.main_dataset`\n",
    "WHERE activity_date < '2017-05-04'\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery Agroup\n",
    "SELECT \n",
    "  playerid,\n",
    "  activity_date,\n",
    "  purchases,\n",
    "  gameends,\n",
    "  ABgroup,\n",
    "  install_date,\n",
    "  conversion_date\n",
    "FROM `XXXXX.abtest.main_dataset`\n",
    "WHERE activity_date >= '2017-05-04' AND  ABgroup = 'A'\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery Bgroup\n",
    "SELECT \n",
    "  playerid,\n",
    "  activity_date,\n",
    "  purchases,\n",
    "  gameends,\n",
    "  ABgroup,\n",
    "  install_date,\n",
    "  conversion_date\n",
    "FROM `XXXXX.abtest.main_dataset`\n",
    "WHERE activity_date >= '2017-05-04' AND  ABgroup = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline metrics:  \n",
    "- Average purchases prior to the test\n",
    "- Average gameends prior to the test\n",
    "- Standar deviation of population purchases (since the sample is big enough I'll use sample's standar deviation prior to the test)\n",
    "- Standar deviation of population gameends (since the sample is big enough I'll use sample's standar deviation prior to the test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''Average purchases prior to the test: {}\n",
    "Average gameends prior to the test: {}\n",
    "Standard deviation of population purchases: {}\n",
    "Standard deviation of population purchases: {}\n",
    "'''.format(np.mean(pre_test_activity.purchases), np.mean(pre_test_activity.gameends), statistics.stdev(pre_test_activity.purchases),  statistics.stdev(pre_test_activity.gameends)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test metrics:  \n",
    "- Sample size Bgroup\n",
    "- Average purchases Agroup\n",
    "- Average purchases Bgroup\n",
    "- Average gameends Agroup\n",
    "- Average gameends Bgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''Sample size Bgroup: {}  \n",
    "Average purchases Bgroup: {}\n",
    "Average gameends Bgroup: {}\n",
    "Standard deviation Bgroup purchases: {}\n",
    "Standard deviation Bgroup gameends: {}\n",
    "Average purchases Agroup: {}\n",
    "Average gameends Agroup: {}\n",
    "'''.format(Bgroup.count(), np.mean(Bgroup.purchases), np.mean(Bgroup.gameends), statistics.stdev(Bgroup.purchases), statistics.stdev(Bgroup.gameends), np.mean(Bgroup.purchases), np.mean(Agroup.gameends)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before extracting insights from the A/B test results I conducted an Hypothesis testing to understand if the effects seen in the test results were statistically significant.  \n",
    "\n",
    "I set a significance level of 5% so the risk of a false positive would be very unlikelly. The test was a one-tail test, meaning that the rejetion region for the Null Hypothesis goes from the critical value to the infinite.\n",
    "\n",
    "Hypothesis for purchases:\n",
    "\n",
    "The Null Hypothesis, the one that states that the effect shown in AB test results is mere chance, says as follows:  \n",
    "- The average purchase metric for the XXXXX game is 0.03061 so an increase of average purchases is product of the variability of data and chance.   \n",
    "\n",
    "The Alternative Hypothesis, the one that allowes me to confidently extract insights of the AB test results, says as follows:  \n",
    "- The introduction of a new feature in the XXXXX game produced an increase in the average purchase metric setting it above 0.03061."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Null Hypothesis = H_0: \\mu = 0.03061$$  \n",
    "$$ Alternative Hypothesis = H_1: \\mu > 0.03061$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the rejection region for the Null Hypothesis started at z= 1.64 wich was the zscore value in the table of normal distribution acumulatin an area of 0.5 to the right.  \n",
    "If the Test Statistic was greater than the z-value, thus falling in the rejection region, the Null Hypothesis would be rejected and so the AB test results would be statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Test Statistic = z= \\frac{\\overline{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ \\overline{X} = 0.03265  \n",
    "\\ \\mu = 0.03061  \n",
    "\\ \\sigma = 0.7715  \n",
    "\\ n = 24833647$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.176937583689883\n"
     ]
    }
   ],
   "source": [
    "z = (0.03265-0.03061)/(0.7715/(np.sqrt(24833647)))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test statistic value falling inside the rejection region, the Null Hypothesis was rejected and the Alternative Hypothesis was accepted meaning that the tested effect was statistically significant.\n",
    "- The introduction of a new feature in the XXXX game produced an increase in the average purchase metric setting it above 0.03061."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis for gameends:  \n",
    "\n",
    "The Null Hypothesis, the one that states that the effect shown in AB test results is mere chance, says as follows:  \n",
    "- The average gameends metric for the XXXXXX game is 13.1803 and a decrease of average gameends is product of the variability of data and chance.  \n",
    "\n",
    "The Alternative Hypothesis, the one that allowes me to confidently extract insights of the AB test results, says as follows:  \n",
    "- The introduction of a new feature in the XXXXX game produced a decrease in the average gameends metric setting it below 13.1803."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Null Hypothesis = H_0: \\mu = 13.1803$$  \n",
    "$$ Alternative Hypothesis = H_1: \\mu < 13.1803 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the rejection region for the Null Hypothesis started at z= -1.64 wich was the value in the zscore table of normal distribution which acumulates an area of 0.5 to the left.  \n",
    "If the Test Statistic was greater than the z-value, thus falling in the rejection region, the Null Hypothesis was rejected and the AB test results would be statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Test Statistic = z= \\frac{\\overline{X}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ \\overline{X} = 12.9323  \n",
    "\\ \\mu = 13.1803  \n",
    "\\ \\sigma = 10.2361  \n",
    "\\ n = 24833647$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-120.73617487984009"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(12.9323-13.1803)/(10.2361/(np.sqrt(24833647)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test statistic value falling inside the rejection region, the Null Hypothesis was rejected and the Alternative Hypothesis was accepted meaning that the tested effect was statistically significant.\n",
    "- The introduction of a new feature in the XXXXXX game produced a decrease in the average gameends metric setting it below 13.1803."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, it seems both effects produced by the experience modification of the game in group B are strong enough to consider them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important disclaimer**   \n",
    "The results of this hypothesis testing are arguably not conclusive because the distribution of the population's data wasn't normal as the purchase data presented extreme skewness. \n",
    "Aditional transformation of the data or more specific tests should be made in order to produce more conclusive results.\n",
    "For this exercise I'll assume the distributions were normal since the sample sizes were big enough and I think a more complicated analysis would fall outside the scoope of the test for my candidacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've concluded that the effects of the A/B test are statistically significant I can proceed to extract insights from them.  \n",
    "For this I used the visualization software Tableau Desktop connected to the BigQuery server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchases metric \n",
    "The new game experience had a noticeable effect on the purchase metric. **B Group average purchase is above baseline average by 6.6%** (0.03265/0.03061= 1.066). Control group was slightly below baseline average by 0.5%.  \n",
    "\n",
    "Interestingly, disaggregating the metric on a daily basis showed that the effect was stronger on the first half of the AB test and lost strength throughout the secong half falling near the daily baseline average. Control group stayed near the baseline  daily average purchase as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Dashboard1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect could also be noticed comparing the total daily purchases within group B before and after the start of the AB test. Showing an **13% increase** from daily totals around 37645 to daily totals around 42675. Control group showed no significant change as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Dashboard1.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the side of game ends   \n",
    "There was an noticeable effect in engagement after the introduction of the new game experience in group B. The **average game ends droped 1.83%**, from 13.1803 baseline metric to 12.9324 B group average game ends.\n",
    "\n",
    "By disaggregating on a daily basis was noticeable that the daily average game ends metric droped rapidly since the introduction of the new experience to the group B. Control group stayed near the baseline value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Dashboard2.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmented by player aging (install date)  \n",
    "A possible segmentation of players could have been by seniority (aging) since the installation day. \n",
    "\n",
    "On the side of purchases the same pattern of rapid increase at start and then slow remision to the baseline happened in the three older groups. Nonetheless, taking into account total average the \"Mature players\" group showed higher receptivity to the new experience, being the group with highest average purchase. Control group stayed near the baseline except for the oldest segment which seemed to be a little farther from the baseline but not enough to consider it significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Dashboard3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation for engagement didn't show significant variations throughout the segments except for \"Fresh\" players. A possible explanation for this could have been that very new players (less than a week) didn't have a comparison point in the past, so they couldn't notice the effect negative effect of sudden increased difficulty. This assumption should be investigated in more dept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Dashboard4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final conclusion and recomendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight, the new experience had a positive effect on the game, as the increase on the revenue was greater than the decrease in engagement.  \n",
    "Nonetheless, it is possible that the detected revenue effect could dissipate over time. For instance, the initial increase in purchases may be due to the player's delay in adjusting to the new increased difficulty. After some time, the players could learn to play better and stop purchasing help to continue playing.  \n",
    "On the other hand, the negative effect on engagement seemed to be more persistent on the long run. If proven, the decision to use the group B experience wouldn't be correct. To infer if these effects could be long lasting I would increase the length of the AB test.  \n",
    "Deeper investigation will be needed to asses this intuitions.  \n",
    "In any case, I recommend performing the test for a greater number of days to better understand the duration of the effects produced by the treatment. In addition, perform a 50/50 split for test and control group to facilitate the comparison of total quantities.\n",
    "\n",
    "Perhaps giving the option for watching a short add instead of paying currency could lessen the negative impact in engagement. There is a huge majority of casual players who will avoid investing real money in a game but are used to watch advertisements constantly and that won't be an issue to them. Besides, a dollar for a south american player has a higher value relatively to a USA player or an Australian player, but watching an add just cost them seconds, a currency that given the case could be perceived as costless in comparison to real life money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
